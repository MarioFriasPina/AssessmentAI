{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3915d7fa",
   "metadata": {},
   "source": [
    "# Car Racing Training\n",
    "\n",
    "### Pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e287218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!apt-get update\n",
    "#!apt-get install -y swig python3-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8c0a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\n",
    "# !pip install -r requirements.txt\n",
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414e6e9f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6dc120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement\n",
    "\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f44e0d",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "125c578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Directory where we save the outputs of this training\n",
    "runDir = f'./checkpoints/{uuid.uuid4()}'\n",
    "os.makedirs(runDir, exist_ok=True)\n",
    "\n",
    "# Save the monitor logs into a csv file\n",
    "train_monitor_file = os.path.join(runDir, \"train_monitor.csv\")\n",
    "\n",
    "total_timesteps = 1_048_576   # Training Steps\n",
    "n_eval_episodes = 8        # Eval Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43cbb2e",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b4f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training environment\n",
    "env_train = gym.make(\"CarRacing-v3\", render_mode=\"rgb_array\")\n",
    "env_train = Monitor(env_train, filename=train_monitor_file)\n",
    "\n",
    "stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=32, min_evals=128, verbose=0)\n",
    "eval_callback = EvalCallback(env_train, eval_freq=1024, best_model_save_path=runDir, log_path=runDir, deterministic=True, render=False, callback_after_eval=stop_train_callback, verbose=0)\n",
    "\n",
    "# PPO Model\n",
    "model = PPO(\n",
    "    policy=\"CnnPolicy\",\n",
    "    env=env_train,\n",
    "    verbose=0,\n",
    "    tensorboard_log=runDir,\n",
    "    n_steps=1024,\n",
    "    learning_rate=1e-4,\n",
    "    batch_size=128,\n",
    "    n_epochs=8,\n",
    "    gamma=0.99,\n",
    "    ent_coef=0.01,\n",
    "    clip_range=0.2,\n",
    "    gae_lambda=0.95,\n",
    ")\n",
    "\n",
    "# tensorboard --logdir AI/checkpoints/\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=total_timesteps, progress_bar=True, callback=eval_callback)\n",
    "\n",
    "# Save the model\n",
    "model_path = f\"{runDir}/final_ppo_carracing\"\n",
    "model.save(model_path)\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c638907",
   "metadata": {},
   "source": [
    "### Training graphical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccce764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read monitor csv\n",
    "df_train = pd.read_csv(train_monitor_file, skiprows=1)\n",
    "rewards_train = df_train[\"r\"].values\n",
    "episodes_train = np.arange(1, len(rewards_train) + 1)\n",
    "\n",
    "# Moving average\n",
    "window = 50\n",
    "if len(rewards_train) >= window:\n",
    "    mov_avg = np.convolve(rewards_train, np.ones(window) / window, mode=\"valid\")\n",
    "else:\n",
    "    mov_avg = None\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(episodes_train, rewards_train, label=\"Episode Reward\", color=\"tab:blue\")\n",
    "if mov_avg is not None:\n",
    "    plt.plot(episodes_train[window-1:], mov_avg,\n",
    "             label=f\"Moving average ({window} ep)\", color=\"tab:orange\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Total Reward\")\n",
    "plt.title(\"CarRacing: Training Reward\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.savefig(f\"{runDir}/plot.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11482c9b",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a30998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load last model\n",
    "eval_env = gym.make(\"CarRacing-v3\", render_mode=\"human\")\n",
    "env_train = TransformedEnv(eval_env,\n",
    "    Compose(\n",
    "        DoubleToFloat(),\n",
    "        ToTensorImage(),\n",
    "        GrayScale(),\n",
    "        UnsqueezeTransform(-4),\n",
    "        CatFrames(dim=-3, N=4),\n",
    "        # ObservationNorm(in_keys=[\"pixels\"]),\n",
    "        # StepCounter()\n",
    "    )\n",
    ")\n",
    "\n",
    "model = PPO.load(model_path, env=eval_env)\n",
    "\n",
    "# Manual evaluation loop\n",
    "rewards_eval = []\n",
    "for epi in range(n_eval_episodes):\n",
    "    obs, _ = eval_env.reset()\n",
    "    done = False\n",
    "    total_r = 0.0\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, r, terminated, truncated, info = eval_env.step(action)\n",
    "        done = terminated or truncated\n",
    "        total_r += r\n",
    "\n",
    "    rewards_eval.append(total_r)\n",
    "\n",
    "rewards_eval = np.array(rewards_eval)\n",
    "episodes_eval = np.arange(1, n_eval_episodes + 1)\n",
    "mean_eval = rewards_eval.mean()\n",
    "std_eval = rewards_eval.std()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(episodes_eval, rewards_eval, '-o', color=\"tab:green\",\n",
    "         label=\"Episode rewards\")\n",
    "plt.axhline(mean_eval, color=\"tab:red\", linestyle=\"--\",\n",
    "            label=f\"Average: {mean_eval:.2f} ± {std_eval:.2f}\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Total Rewards\")\n",
    "plt.title(f\"CarRacing: Evaluation in {n_eval_episodes} episodes\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Eval → Average Reward: {mean_eval:.2f}; Standard Deviation: {std_eval:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
