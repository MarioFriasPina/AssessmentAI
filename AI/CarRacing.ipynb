{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "YOJvphymrXVe",
      "metadata": {
        "id": "YOJvphymrXVe"
      },
      "outputs": [],
      "source": [
        "#!apt-get update\n",
        "#!apt-get install -y swig python3-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c0b813e7",
      "metadata": {
        "id": "c0b813e7"
      },
      "outputs": [],
      "source": [
        "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\n",
        "# !pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36960300",
      "metadata": {
        "id": "36960300"
      },
      "source": [
        "## PPO Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4dc4177d",
      "metadata": {
        "id": "4dc4177d"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from torch import multiprocessing\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "# Information\n",
        "from IPython.display import clear_output, display\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Torch\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.distributions import OneHotCategorical\n",
        "\n",
        "# TorchRL\n",
        "from torchrl.envs.transforms import (\n",
        "    TransformedEnv, Compose, ToTensorImage, ObservationNorm, StepCounter, DoubleToFloat, GrayScale, CatFrames, UnsqueezeTransform\n",
        "    )\n",
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data.replay_buffers import ReplayBuffer\n",
        "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
        "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
        "from torchrl.modules import ProbabilisticActor, SafeModule, ValueOperator\n",
        "from torchrl.envs.utils import ExplorationType, set_exploration_type\n",
        "from torchrl.objectives import ClipPPOLoss\n",
        "from torchrl.objectives.value import GAE\n",
        "\n",
        "# Environment\n",
        "from torchrl.envs.libs.gym import GymEnv\n",
        "\n",
        "# Other\n",
        "import uuid\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7882c92",
      "metadata": {
        "id": "c7882c92"
      },
      "source": [
        "### Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fd75e3ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd75e3ec",
        "outputId": "d04d01c7-b590-4c2b-f424-c0d3526bad5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
        "device = (\n",
        "    torch.device(0)\n",
        "    if torch.cuda.is_available() and not is_fork\n",
        "    else torch.device(\"cpu\")\n",
        ")\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Collector hyper-parameters\n",
        "frames_per_batch = 1024 # number of frames collected per batch\n",
        "num_iterations = 256 # number of batches\n",
        "\n",
        "total_frames = num_iterations * frames_per_batch  # total number of frames to collect\n",
        "\n",
        "# PPO hyper-parameters\n",
        "sub_batch_size = 64  # cardinality of the sub-samples gathered from the current data in the inner loop\n",
        "num_epochs = 4 # optimization steps per batch of data collected\n",
        "\n",
        "# Checkpoint saving parameters\n",
        "checkpoint_interval = 16\n",
        "filename = \"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5af235e9",
      "metadata": {
        "id": "5af235e9"
      },
      "source": [
        "### Creating the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6b586b0b",
      "metadata": {
        "id": "6b586b0b"
      },
      "outputs": [],
      "source": [
        "base_env = GymEnv(\"CarRacing-v3\", continuous=False, render_mode=\"rgb_array\", device=device)\n",
        "\n",
        "# Compose them into a TransformedEnv\n",
        "env = TransformedEnv(base_env,\n",
        "    Compose(\n",
        "        DoubleToFloat(),\n",
        "        ToTensorImage(),\n",
        "        GrayScale(),\n",
        "        #UnsqueezeTransform(-4),\n",
        "        #CatFrames(dim=-3, N=4),\n",
        "        ObservationNorm(in_keys=[\"pixels\"]),\n",
        "        StepCounter()\n",
        "    )\n",
        ")\n",
        "\n",
        "# Normalize observations\n",
        "env.transform[-2].init_stats(num_iter=128, reduce_dim=0, cat_dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94b01750",
      "metadata": {
        "id": "94b01750"
      },
      "source": [
        "### Creating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d1b51dd4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1b51dd4",
        "outputId": "5b960600-886e-4f6b-e863-5678cdf6b830"
      },
      "outputs": [],
      "source": [
        "class CarRacingBackbone(nn.Module):\n",
        "    def __init__(self, n_actions: int, n_frames: int = 1, img_size: tuple = (96, 96)):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(n_frames, 32, kernel_size=8, stride=4, device=device)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2, device=device)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, device=device)\n",
        "\n",
        "        # Dynamically compute flatten_size so we never hard‐code incorrectly:\n",
        "        H, W = img_size\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.zeros(1, n_frames, H, W, device=device)  # [1, 3, 96, 96]\n",
        "            o = self.conv1(dummy)\n",
        "            o = self.conv2(o)\n",
        "            o = self.conv3(o)\n",
        "            self.flatten_size = o.view(1, -1).shape[1]  # e.g. 4096\n",
        "\n",
        "        self.fc1 = nn.Linear(self.flatten_size, 512, device=device)\n",
        "        self.logits = nn.Linear(512, n_actions, device=device)\n",
        "\n",
        "    def forward(self, obs: torch.Tensor):\n",
        "        # If obs has shape [3, 96, 96], unsqueeze so it becomes [1, 3, 96, 96]:\n",
        "        if obs.dim() == 3:                     # no batch dimension\n",
        "            obs = obs.unsqueeze(0)             # now [1, 3, 96, 96]\n",
        "\n",
        "        # By this point, obs must be [B, 3, 96, 96]:\n",
        "        x = torch.relu(self.conv1(obs))        # → [B, 32, 23, 23]\n",
        "        x = torch.relu(self.conv2(x))          # → [B, 64, 10, 10]\n",
        "        x = torch.relu(self.conv3(x))          # → [B, 64,  8,  8]\n",
        "        x = x.reshape(x.shape[0], -1)             # → [B, 4096]  (because flatten_size = 4096)\n",
        "        x = torch.relu(self.fc1(x))            # → [B, 512]\n",
        "        return self.logits(x)                  # → [B, n_actions]\n",
        "\n",
        "backbone_net = SafeModule(\n",
        "    module=CarRacingBackbone(env.action_spec.shape.numel()),\n",
        "    in_keys=[\"pixels\"],     # expects obs under key \"pixels\"\n",
        "    out_keys=[\"logits\"],    # produces a \"logits\" tensor\n",
        ")\n",
        "\n",
        "discrete_actor = ProbabilisticActor(\n",
        "    module=backbone_net,\n",
        "    spec=env.action_spec,               # DiscreteTensorSpec\n",
        "    in_keys=[\"logits\"],                 # read logits from that key\n",
        "    distribution_class=OneHotCategorical,     # TorchRL’s one-hot categorical: samples a one-hot vector of size n_actions\n",
        "    out_keys=[\"action\"],                # writes a one-hot action into \"action\"\n",
        "    return_log_prob=True,               # store \"log_prob\" in the tensordict\n",
        ")\n",
        "\n",
        "critic_net = SafeModule(\n",
        "    module=CarRacingBackbone(1),\n",
        "    in_keys=[\"pixels\"],\n",
        "    out_keys=[\"state_value\"],\n",
        ")\n",
        "critic = ValueOperator(\n",
        "    module=critic_net,\n",
        "    in_keys=[\"pixels\"],\n",
        "    out_keys=[\"state_value\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a59bd47",
      "metadata": {
        "id": "9a59bd47"
      },
      "source": [
        "### Data Collector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f37e84c1",
      "metadata": {
        "id": "f37e84c1"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Failed while executing module '0'. Scroll up for more info.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[31mRuntimeError\u001b[39m: TensorDictModule failed with operation\n    CarRacingBackbone(\n      (conv1): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n      (conv2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n      (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n      (fc1): Linear(in_features=4096, out_features=512, bias=True)\n      (logits): Linear(in_features=512, out_features=5, bias=True)\n    )\n    in_keys=['pixels']\n    out_keys=['logits'].",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/tensordict/nn/sequence.py:624\u001b[39m, in \u001b[36mTensorDictSequential.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, **kwargs)\u001b[39m\n\u001b[32m    623\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m     tensordict_exec = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict_exec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/tensordict/nn/sequence.py:570\u001b[39m, in \u001b[36mTensorDictSequential._run_module\u001b[39m\u001b[34m(self, module, tensordict, **kwargs)\u001b[39m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.partial_tolerant \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m    568\u001b[39m     key \u001b[38;5;129;01min\u001b[39;00m tensordict.keys(include_nested=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module.in_keys\n\u001b[32m    569\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m     tensordict = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.partial_tolerant \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensordict, LazyStackedTensorDict):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/tensordict/nn/common.py:328\u001b[39m, in \u001b[36mdispatch.__call__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, *args, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/tensordict/nn/utils.py:373\u001b[39m, in \u001b[36m_set_skip_existing_None.__call__.<locals>.wrapper\u001b[39m\u001b[34m(_self, tensordict, *args, **kwargs)\u001b[39m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/tensordict/nn/common.py:1239\u001b[39m, in \u001b[36mTensorDictModule.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[39m\n\u001b[32m   1238\u001b[39m out_keys = indent(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mout_keys=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.out_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[32m4\u001b[39m * \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1240\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTensorDictModule failed with operation\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00min_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mout_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1241\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/tensordict/nn/common.py:1211\u001b[39m, in \u001b[36mTensorDictModule.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[39m\n\u001b[32m   1210\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1211\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m   1212\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors_out, (\u001b[38;5;28mdict\u001b[39m, TensorDictBase)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m   1213\u001b[39m     key \u001b[38;5;129;01min\u001b[39;00m tensors_out \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.out_keys\n\u001b[32m   1214\u001b[39m ):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/tensordict/nn/common.py:1195\u001b[39m, in \u001b[36mTensorDictModule.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[39m\n\u001b[32m   1194\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1195\u001b[39m     tensors_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1196\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tensors_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/tensordict/nn/common.py:1154\u001b[39m, in \u001b[36mTensorDictModule._call_module\u001b[39m\u001b[34m(self, tensors, **kwargs)\u001b[39m\n\u001b[32m   1153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1154\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mCarRacingBackbone.forward\u001b[39m\u001b[34m(self, obs)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# By this point, obs must be [B, 3, 96, 96]:\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m x = torch.relu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m)        \u001b[38;5;66;03m# → [B, 32, 23, 23]\u001b[39;00m\n\u001b[32m     27\u001b[39m x = torch.relu(\u001b[38;5;28mself\u001b[39m.conv2(x))          \u001b[38;5;66;03m# → [B, 64, 10, 10]\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mRuntimeError\u001b[39m: Given groups=1, weight of size [32, 4, 8, 8], expected input[1, 1, 96, 96] to have 4 channels, but got 1 channels instead",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m replay_buffer = ReplayBuffer(\n\u001b[32m      2\u001b[39m     storage=LazyTensorStorage(max_size=frames_per_batch, device=device),\n\u001b[32m      3\u001b[39m     sampler=SamplerWithoutReplacement(),\n\u001b[32m      4\u001b[39m     batch_size=sub_batch_size,\n\u001b[32m      5\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m collector = \u001b[43mSyncDataCollector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdiscrete_actor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframes_per_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframes_per_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtotal_frames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43msplit_trajs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m gae_module = GAE(\n\u001b[32m     17\u001b[39m     value_network=critic,\n\u001b[32m     18\u001b[39m     gamma=\u001b[32m0.99\u001b[39m,\n\u001b[32m     19\u001b[39m     lmbda=\u001b[32m0.95\u001b[39m,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_entropy_coef\u001b[39m(iteration, total_iters):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/torchrl/collectors/collectors.py:882\u001b[39m, in \u001b[36mSyncDataCollector.__init__\u001b[39m\u001b[34m(self, create_env_fn, policy, policy_factory, frames_per_batch, total_frames, device, storing_device, policy_device, env_device, create_env_kwargs, max_frames_per_traj, init_random_frames, reset_at_each_iter, postproc, split_trajs, exploration_type, return_same_td, reset_when_done, interruptor, set_truncated, use_buffers, replay_buffer, extend_buffer, trust_policy, compile_policy, cudagraph_policy, no_cuda_sync, weight_updater, **kwargs)\u001b[39m\n\u001b[32m    879\u001b[39m \u001b[38;5;28mself\u001b[39m.set_truncated = set_truncated\n\u001b[32m    881\u001b[39m \u001b[38;5;28mself\u001b[39m._make_shuttle()\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_make_final_rollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmake_rollout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_use_buffers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[38;5;28mself\u001b[39m._set_truncated_keys()\n\u001b[32m    885\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m split_trajs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/torchrl/collectors/collectors.py:995\u001b[39m, in \u001b[36mSyncDataCollector._maybe_make_final_rollout\u001b[39m\u001b[34m(self, make_rollout)\u001b[39m\n\u001b[32m    993\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compiled_policy:\n\u001b[32m    994\u001b[39m     cudagraph_mark_step_begin()\n\u001b[32m--> \u001b[39m\u001b[32m995\u001b[39m policy_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[38;5;66;03m# check that we don't have exclusive keys, because they don't appear in keys\u001b[39;00m\n\u001b[32m    998\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_exclusive\u001b[39m(val):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/tensordict/nn/common.py:328\u001b[39m, in \u001b[36mdispatch.__call__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, *args, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/tensordict/nn/utils.py:373\u001b[39m, in \u001b[36m_set_skip_existing_None.__call__.<locals>.wrapper\u001b[39m\u001b[34m(_self, tensordict, *args, **kwargs)\u001b[39m\n\u001b[32m    371\u001b[39m \u001b[38;5;28mself\u001b[39m.prev = _skip_existing.get_mode()\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    375\u001b[39m     _skip_existing.set_mode(\u001b[38;5;28mself\u001b[39m.prev)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/tensordict/nn/probabilistic.py:1338\u001b[39m, in \u001b[36mProbabilisticTensorDictSequential.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, **kwargs)\u001b[39m\n\u001b[32m   1334\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1335\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed while executing module \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_num_or_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Scroll up for more info.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1336\u001b[39m             ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1337\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1338\u001b[39m     tensordict_exec = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_dist_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict_exec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1339\u001b[39m     tensordict_exec = \u001b[38;5;28mself\u001b[39m._last_module(\n\u001b[32m   1340\u001b[39m         tensordict_exec, _requires_sample=\u001b[38;5;28mself\u001b[39m._requires_sample\n\u001b[32m   1341\u001b[39m     )\n\u001b[32m   1343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.inplace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/tensordict/nn/probabilistic.py:1089\u001b[39m, in \u001b[36mProbabilisticTensorDictSequential.get_dist_params\u001b[39m\u001b[34m(self, tensordict, tensordict_out, **kwargs)\u001b[39m\n\u001b[32m   1087\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCould not find a default interaction in the modules.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1088\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_interaction_type(\u001b[38;5;28mtype\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1089\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/tensordict/nn/common.py:328\u001b[39m, in \u001b[36mdispatch.__call__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, *args, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/tensordict/nn/utils.py:373\u001b[39m, in \u001b[36m_set_skip_existing_None.__call__.<locals>.wrapper\u001b[39m\u001b[34m(_self, tensordict, *args, **kwargs)\u001b[39m\n\u001b[32m    371\u001b[39m \u001b[38;5;28mself\u001b[39m.prev = _skip_existing.get_mode()\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    375\u001b[39m     _skip_existing.set_mode(\u001b[38;5;28mself\u001b[39m.prev)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AssessmentAI/.venv/lib/python3.12/site-packages/tensordict/nn/sequence.py:629\u001b[39m, in \u001b[36mTensorDictSequential.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, **kwargs)\u001b[39m\n\u001b[32m    627\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    628\u001b[39m             module_num_or_key = \u001b[38;5;28mself\u001b[39m._get_module_num_or_key(module)\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    630\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed while executing module \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_num_or_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Scroll up for more info.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    631\u001b[39m             ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    633\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    634\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTensorDictSequential does not support keyword arguments other than \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtensordict_out\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or in_keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.in_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs.keys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    635\u001b[39m     )\n",
            "\u001b[31mRuntimeError\u001b[39m: Failed while executing module '0'. Scroll up for more info."
          ]
        }
      ],
      "source": [
        "replay_buffer = ReplayBuffer(\n",
        "    storage=LazyTensorStorage(max_size=frames_per_batch, device=device),\n",
        "    sampler=SamplerWithoutReplacement(),\n",
        "    batch_size=sub_batch_size,\n",
        ")\n",
        "\n",
        "collector = SyncDataCollector(\n",
        "    env,\n",
        "    policy=discrete_actor,\n",
        "    frames_per_batch=frames_per_batch,\n",
        "    total_frames=total_frames,\n",
        "    device=device,\n",
        "    split_trajs=False,\n",
        ")\n",
        "\n",
        "gae_module = GAE(\n",
        "    value_network=critic,\n",
        "    gamma=0.99,\n",
        "    lmbda=0.95,\n",
        ")\n",
        "\n",
        "def get_entropy_coef(iteration, total_iters):\n",
        "    if iteration < 0.2 * total_iters:\n",
        "        return 0.05\n",
        "    elif iteration < 0.5 * total_iters:\n",
        "        return 0.02\n",
        "    else:\n",
        "        return 0.01\n",
        "\n",
        "ppo_loss = ClipPPOLoss(\n",
        "    actor_network=discrete_actor,\n",
        "    critic_network=critic,\n",
        "    clip_epsilon=0.2,\n",
        "    loss_critic_type=\"smooth_l1\",\n",
        "    \n",
        "    #normalize_advantage=True,\n",
        "\n",
        "    entropy_coef=get_entropy_coef(0, num_iterations),\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.AdamW(ppo_loss.parameters(), lr=3e-4)\n",
        "\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ChainedScheduler([\n",
        "    torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1e-2, total_iters=int(0.1 * num_iterations)), # First 10% of the training\n",
        "    torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=int(0.9 * num_iterations), eta_min=1e-8), # Last 90% of the training\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "375cea7d",
      "metadata": {
        "id": "375cea7d"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cZeNveQfv-Tk",
      "metadata": {
        "id": "cZeNveQfv-Tk"
      },
      "outputs": [],
      "source": [
        "def plot(logs):\n",
        "    # Update plot data\n",
        "    clear_output(wait=True)\n",
        "\n",
        "    # Rebuild the figure from scratch\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
        "    axes = axes.flatten()\n",
        "    titles = [\n",
        "        \"Avg Reward (Train)\", \"Avg Reward (Eval)\",\n",
        "        #\"Min Steps (Train)\", \"Max Steps (Train)\",\n",
        "    ]\n",
        "    data = [\n",
        "        (logs[\"train_reward\"],   \"blue\"),\n",
        "        (logs[\"eval_reward\"],    \"green\"),\n",
        "        #(logs[\"train_steps_min\"],    \"red\"),\n",
        "        #(logs[\"train_steps_max\"],     \"orange\"),\n",
        "    ]\n",
        "\n",
        "    for ax, title, (y, color) in zip(axes, titles, data):\n",
        "        ax.plot(y, color=color)\n",
        "        ax.set_title(title)\n",
        "        ax.relim()\n",
        "        ax.autoscale_view()\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Display the new figure\n",
        "    display(fig)\n",
        "    plt.close(fig)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f654737",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "id": "5f654737",
        "outputId": "4f1d13c9-65f1-4525-90dc-b8256cc203a6"
      },
      "outputs": [],
      "source": [
        "pbar = tqdm(total=num_iterations)\n",
        "pbar.set_description(\"Training \")\n",
        "logs = defaultdict(list)\n",
        "\n",
        "runDir = f'./checkpoints/{uuid.uuid4()}'\n",
        "os.mkdir(runDir)\n",
        "\n",
        "for i, td in enumerate(collector):\n",
        "    # Compute advantage + value targets\n",
        "    td = gae_module(td)\n",
        "\n",
        "    # Normalize Advantages\n",
        "    # adv = td[\"advantage\"]\n",
        "    # adv = (adv - adv.mean()) / (adv.std() + 1e-8)\n",
        "    # td.set(\"advantage\", adv)\n",
        "\n",
        "    # Update entropy coefficient\n",
        "    with torch.no_grad():\n",
        "        coef = get_entropy_coef(i, num_iterations)\n",
        "        ppo_loss.entropy_coef.copy_(torch.tensor(coef, device=ppo_loss.entropy_coef.device))\n",
        "\n",
        "    # Sample minibatches\n",
        "    replay_buffer.extend(td)\n",
        "\n",
        "    for _ in range(num_epochs):\n",
        "        sample_td = replay_buffer.sample()\n",
        "\n",
        "        # Compute loss\n",
        "        loss_vals = ppo_loss(sample_td)\n",
        "        loss_value = (\n",
        "            loss_vals[\"loss_objective\"]\n",
        "            + loss_vals[\"loss_critic\"]\n",
        "            + loss_vals[\"loss_entropy\"]\n",
        "        )\n",
        "\n",
        "        # Backpropagate and optimize\n",
        "        loss_value.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(ppo_loss.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    replay_buffer.empty()\n",
        "\n",
        "    logs[\"train_reward\"].append(td[\"next\", \"reward\"].mean().item())\n",
        "\n",
        "    if i % checkpoint_interval == 0:\n",
        "        # Save the evaluation data\n",
        "        with (set_exploration_type(ExplorationType.DETERMINISTIC)), torch.no_grad():\n",
        "          # Run the env with the actors value\n",
        "          eval_rollout = env.rollout(1024, discrete_actor)\n",
        "\n",
        "          # Save the evaluation data\n",
        "          logs[\"eval_reward\"].append( eval_rollout[\"next\", \"reward\"].mean().item() )\n",
        "          #logs[\"eval_steps\"].append( eval_rollout[\"step_count\"].min().item() )\n",
        "          del eval_rollout\n",
        "\n",
        "          # Save a checkpoint\n",
        "          filename = f'{runDir}/{i}.ch'\n",
        "          checkpoint = {\n",
        "              'model_state_dict': discrete_actor.module.state_dict(),\n",
        "          }\n",
        "\n",
        "          torch.save(checkpoint, filename)\n",
        "\n",
        "    pbar.set_description(\"Training \")\n",
        "\n",
        "    plot(logs)\n",
        "\n",
        "    pbar.update(1)\n",
        "\n",
        "    scheduler.step()\n",
        "pbar.close()\n",
        "\n",
        "# Final save of the model\n",
        "filename = f'{runDir}/_final.ch'\n",
        "checkpoint = {\n",
        "    'model_state_dict': discrete_actor.module.state_dict(),\n",
        "}\n",
        "torch.save(checkpoint, filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8b0eb4a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(f'{runDir}/_logs.json', 'w') as json_file:\n",
        "    json.dump(logs, json_file, indent=4)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
